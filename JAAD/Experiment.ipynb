{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process pedestrian JSON file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from matplotlib.pyplot import figure, imshow, savefig\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dict_filename = 'pedestrian_dataset_folds/fold_dict.json'\n",
    "fold_dict = json.load(open(fold_dict_filename, 'r'))\n",
    "num_frames = 30\n",
    "frames_to_process = set()\n",
    "for json_filename in fold_dict:\n",
    "    json_path = os.path.join(fold_dict[json_filename], json_filename)\n",
    "    ped_json = json.load(open(json_path, 'r'))\n",
    "    video_name = ped_json['video']\n",
    "    first_frame = ped_json['frame_data'][0]\n",
    "    start = first_frame['frame_index']\n",
    "    for idx in range(start, start + num_frames):\n",
    "        frames_to_process.add(video_name + '-' + str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dict = {}\n",
    "for frame in frames_to_process:\n",
    "    video, idx = frame.split('-')\n",
    "    if video not in frames_dict:\n",
    "        frames_dict[video] = []\n",
    "    frames_dict[video].append(int(idx))\n",
    "for video in frames_dict:\n",
    "    frames_dict[video] = sorted(frames_dict[video])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict = {}\n",
    "for video in frames_dict:\n",
    "    if video not in names_dict:\n",
    "        names_dict[video] = []\n",
    "    for idx in frames_dict[video]:  \n",
    "        names_dict[video].append(video + '-' + str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = 'video_0266'\n",
    "video_name = os.path.join('clips', video_id + '.mp4')\n",
    "images = get_video_frames(video_name, frames_dict[video_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in enumerate(i, images):\n",
    "    image_name = names_dict[video_id][i]\n",
    "    test(image, model, 19, image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Append features extracted from segmentation mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filename = 'prediction/video_0225-16.png'\n",
    "bb_top_left = [1200, 657]\n",
    "size = [90, 200]\n",
    "width_limit = 1920\n",
    "height_limit = 1080\n",
    "labels = {\n",
    "    0: 'road', \n",
    "    1: 'sidewalk',\n",
    "    2: 'ignore',\n",
    "    3: 'ignore',\n",
    "    4: 'ignore',\n",
    "    5: 'ignore',\n",
    "    6: 'traffic_light',\n",
    "    7: 'traffic_sign',\n",
    "    8: 'ignore',\n",
    "    9: 'ignore',\n",
    "    10: 'ignore',\n",
    "    11: 'ignore',\n",
    "    12: 'ignore',\n",
    "    13: 'car',\n",
    "    14: 'truck',\n",
    "    15: 'bus',\n",
    "    16: 'train',\n",
    "    17: 'motorcycle',\n",
    "    18: 'bicycle',\n",
    "}\n",
    "\n",
    "convert_id = {\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    6: 2,\n",
    "    7: 3,\n",
    "    13: 4,\n",
    "    14: 4,\n",
    "    15: 4,\n",
    "    16: 4,\n",
    "    17: 4,\n",
    "    18: 4\n",
    "}\n",
    "\n",
    "our_labels = {\n",
    "    0: 'road',\n",
    "    1: 'sidewalk',\n",
    "    2: 'traffic_light',\n",
    "    3: 'traffic_sign',\n",
    "    4: 'vehicle'    \n",
    "}\n",
    "\n",
    "\n",
    "def generate_segmentation_features(filename, bb_top_left, size, percent=0.05):\n",
    "    image = np.array(Image.open(image_filename))\n",
    "    \n",
    "    left_x = bb_top_left[0]\n",
    "    right_x = bb_top_left[0] + size[0]\n",
    "    if right_x > width_limit:\n",
    "        right_x = width_limit\n",
    "    top_y = bb_top_left[1]\n",
    "    bottom_y = bb_top_left[1] + size[1]\n",
    "    if bottom_y > height_limit:\n",
    "        bottom_y = height_limit\n",
    "        \n",
    "    tl = [left_x, top_y]\n",
    "    bl = [left_x, bottom_y]\n",
    "    tr = [right_x, top_y]\n",
    "    br = [right_x, bottom_y]\n",
    "    points = np.array([tl, bl, br, tr], dtype=np.int32)\n",
    "    line_color = (255, 0, 0)\n",
    "    figure(figsize=(10, 10))\n",
    "    imshow(image)\n",
    "    figure(figsize=(10, 10))\n",
    "    image = cv2.polylines(image, [points], True, line_color, 5)\n",
    "    imshow(image)\n",
    "    histogram = {}\n",
    "    for bdd_id in labels:\n",
    "        histogram[bdd_id] = 0\n",
    "    for y in range(top_y, bottom_y):\n",
    "        for x in range(left_x, right_x):\n",
    "            if image[y, x] in histogram:\n",
    "                histogram[image[y, x]] += 1\n",
    "    \n",
    "    our_histogram = {}\n",
    "    for our_id in our_labels:\n",
    "        our_histogram[our_id] = 0\n",
    "    for bdd_id in histogram:\n",
    "        if labels[bdd_id] == 'ignore':\n",
    "            continue\n",
    "        our_histogram[convert_id[bdd_id]] += histogram[bdd_id]\n",
    "    \n",
    "    \n",
    "    threshold = int(size[0] * size[1] * percent)\n",
    "    features = []\n",
    "    for our_id in our_labels:\n",
    "        if our_histogram[our_id] > threshold:\n",
    "            features.append((our_labels[our_id], 1))\n",
    "        else:\n",
    "            features.append((our_labels[our_id], 0))\n",
    "    print(features)\n",
    "generate_segmentation_features(image_filename, bb_top_left, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear classifier on pedestrian feature vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dict = json.load(open(fold_dict_filename))\n",
    "count = 0\n",
    "data = []\n",
    "labels = []\n",
    "for json_filename in fold_dict:\n",
    "    ped_json = json.load(open(os.path.join(fold_dict[json_filename], json_filename)))\n",
    "    ped_id = ped_json['video'] + '-' + ped_json['name']\n",
    "    frame_data = ped_json['frame_data']\n",
    "    \n",
    "    for frame_dict in frame_data:\n",
    "        frame_features = []\n",
    "        frame_features.extend(frame_dict['resnet_feature'][0])\n",
    "        frame_features.extend(frame_dict['attrib_vector'][0])\n",
    "        frame_features.extend(frame_dict['global_cue_vector'])\n",
    "        frame_features.append(int(frame_dict['standing']))\n",
    "        frame_features.append(int(frame_dict['looking'])) \n",
    "        data.append(np.array(frame_features))   \n",
    "        labels.append(int(ped_json['crossing']))\n",
    "\n",
    "        \n",
    "        \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sTr = int(len(data) * 0.8)\n",
    "sTe = int(len(data) * 0.2)\n",
    "xTr = data[:sTr]\n",
    "yTr = labels[:sTr]\n",
    "xTe = data[-sTe:]\n",
    "yTe = labels[-sTe:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training size:\", len(xTr))\n",
    "print(\"Testing  size:\", len(xTe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "filename = \"svm.joblib\"\n",
    "\n",
    "if train:\n",
    "    # Set random_state = 0 for replicable results\n",
    "    classifier = LinearSVC(penalty=\"l1\", dual=False, random_state=0)\n",
    "    classifier.fit(xTr, yTr)\n",
    "    # print(\"Weights: \" + str(classifier.coef_))\n",
    "    joblib.dump(classifier.coef_, filename)\n",
    "else:\n",
    "    classifier = joblib.load(filename)\n",
    "\n",
    "# Evaluate\n",
    "predictions = classifier.predict(xTe)\n",
    "# print(\"Predictions: \" + str(predictions))\n",
    "misclfs = np.sum(predictions != yTe)\n",
    "error = misclfs / len(yTe)\n",
    "print(\"Error: \" + str(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reorganize the mask directory so that masks are in their own video folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_mask_dir(mask_dir):\n",
    "    for filename in os.listdir(mask_dir):\n",
    "        file_path = os.path.join(mask_dir, filename)\n",
    "        dir_name = filename.split('-')[0]\n",
    "        new_filename = str(int(filename.split('-')[1].split('.')[0]) - 1) + '.png'\n",
    "        dir_path = os.path.join(mask_dir, dir_name)\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.mkdir(dir_path)\n",
    "        new_file_path = os.path.join(dir_path, new_filename)\n",
    "        shutil.move(file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorganize_mask_dir('prediction')\n",
    "reorganize_mask_dir('prediction_color')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert mask to include only road and sidewalk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PALETTE = np.array([\n",
    "    [217, 83, 79],\n",
    "    [91, 192, 222],\n",
    "    [0, 0, 0]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "in_dir = 'prediction'\n",
    "out_dir = 'prediction_filtered'\n",
    "for video_dir in os.listdir(in_dir):\n",
    "    for image_name in os.listdir(os.path.join(in_dir, video_dir)):\n",
    "        image_path = os.path.join(in_dir, video_dir, image_name)\n",
    "        image = np.array(Image.open(image_path))\n",
    "        image[np.logical_and(image != 0, image != 1)] = 2\n",
    "        image = PALETTE[image]\n",
    "        new_image_name = image_name.split('.')[0] + '_filtered.png'\n",
    "        new_image_path = os.path.join(out_dir, new_image_name)\n",
    "        Image.fromarray(image).save(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(Image.open('prediction_filtered/4_filtered.png'))\n",
    "points = np.array([[1000, 600], [1200, 600], [1200, 800], [1000, 800]], dtype=np.int32)\n",
    "line_color = (0, 255, 0)\n",
    "image = cv2.polylines(image, [points], True, line_color, 5)\n",
    "figure(figsize=(10, 10))\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate ground truth dictionary to visualize crossing bound boxes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dict = {}\n",
    "\n",
    "fold_dict = json.load(open(fold_dict_filename))\n",
    "for json_filename in fold_dict:\n",
    "    ped_json = json.load(open(os.path.join(fold_dict[json_filename], json_filename)))\n",
    "    label = int(ped_json['crossing']) \n",
    "    \n",
    "    video_id = ped_json['video']\n",
    "    if video_id not in ground_truth_dict:\n",
    "        ground_truth_dict[video_id] = {}\n",
    "    \n",
    "    frame_data = ped_json['frame_data']\n",
    "    for frame in frame_data:\n",
    "        i = frame['frame_index']\n",
    "        if idx not in ground_truth_dict[video_id]:\n",
    "            ground_truth_dict[video_id][i] = {}\n",
    "        if 'labels' not in ground_truth_dict[video_id][i]:\n",
    "            ground_truth_dict[video_id][i]['labels'] = []\n",
    "        if 'bbox' not in ground_truth_dict[video_id][i]:\n",
    "            ground_truth_dict[video_id][i]['bbox'] = []\n",
    "        ground_truth_dict[video_id][i]['labels'].append(label)\n",
    "        bbox = [*frame['bb_top_left'], *frame['bb_bottom_right']]\n",
    "        ground_truth_dict[video_id][i]['bbox'].append(bbox)\n",
    "\n",
    "with open('ground_truth_dict.json', 'w') as f:\n",
    "    json.dump(ground_truth_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
